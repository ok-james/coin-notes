比特币挖矿算法本身没有什么漏洞，但是，在算法之外，有一个饱受争议的问题，就是挖矿设备的专业化，主要是指专门用于挖矿的 ASIC 芯片。很多人认为这个与去中心化的理念是背道而驰的，也是跟比特币的设计初衷是相违背的。

而以太坊希望实现 ASIC resistance ，也就是避免挖矿设备的专业化。

那如何能够设计出一个对 ASIC 芯片不友好的挖矿方式呢？一种常见的做法是增加挖矿对于内存的需求，也就是 memory hard mining puzzle 。ASIC 芯片相比于普通计算机来说，其优点是算力强，但是在内存访问的性能上没有优势。

## 以太坊的 memory puzzle

以太坊使用的是一大一小两个数据集，小的是一个 16M 的 cache ，大的是一个 1G 的 dataset ，称为 DAG ，这 1G 的数据集是从 16M 的 cache 中生成出来的。

为什么要设计成一大一小两个数据集？就是为了便于验证，轻节点只需要保存 16M 的 cache 即可，只有需要挖矿的全节点才需要保存 1G 的数据集。

另外，需要注意，这里提到的 16M 和 1G 这两个大小是会改变的，每产生固定数目的区块以后，就会提高这两个数值。

### 基本思想

如果是全节点，则下面的所有过程都要执行一遍，如果是轻节点，则只需要执行第一步【生成 16M 的 cache】即可。

#### 生成 16M 的 cache

首先需要生成 16M 的 cache ，生成的过程如下：

首先从一个种子 seed 节点开始，经过运算，得到 16M cache 的第一个元素

然后从第一个元素开始，取哈希得到第二个元素，第二个元素取哈希得到第三个元素，以此类推，直到产生 16M cache 的元素为止。

每隔 30000 个块会重新生成 seed （对原来的 seed 求哈希值），并利用新的 seed 生成新的 cache 。

cache 的初始大小为 16M ，每隔 30000 哥块重新生成时增大初始大小的 1/128 —— 128K。

#### 生成 1G 的 dataset

从 16M 的 cache 取出一个数，经过一些计算后，得到下一个数的位置，然后取出该位置的数，再经过相同的计算，得到再下一个数的位置，一共计算 256 次，最后得到的值，作为 1G 的 dataset 中第一个位置的值，然后重复上述的过程，直到将 1G 的 dataset 填满为止。

这个 dataset 叫做 DAG ，初始大小是 1G ，也是每隔 30000 个块更新，同时增大初始大小 1/128——8M。

#### 挖矿

矿工只会用到 1G 的 dataset 。

具体流程是，初始情况下，根据 block header 和 nonce 计算出一个哈希，并作为 1G dataset 的位置读取出该位置以及下一个位置的值，然后对这两个值执行一些计算，从而得到下一个位置，这样循环计算 64 次，最终，用最后一次得到的哈希值与挖矿难度的目标阈值进行比较，确定是否符合挖矿难度。
